images:
  # -- Common tag for Argo Workflows images. Defaults to `.Chart.AppVersion`.
  tag: ""
  # -- imagePullPolicy to apply to all containers
  pullPolicy: Always
  # -- Secrets with credentials to pull images from a private registry
  pullSecrets: []
  # - name: argo-pull-secret

## Custom resource configuration
crds:
  # -- Install and upgrade CRDs
  install: true
  # -- Keep CRDs on chart uninstall
  keep: false
  # -- Annotations to be added to all CRDs
  annotations: {}

# -- Create ClusterRoles that extend existing ClusterRoles to interact with Argo Workflows CRDs.
## Ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles
createAggregateRoles: true

# -- String to partially override "argo-workflows.fullname" template
nameOverride:

# -- String to fully override "argo-workflows.fullname" template
fullnameOverride:

# -- Override the namespace
# @default -- `.Release.Namespace`
namespaceOverride: ""

# -- Labels to set on all resources
commonLabels: {}

# -- Override the Kubernetes version, which is used to evaluate certain manifests
kubeVersionOverride: ""

# Override APIVersions
apiVersionOverrides:
  # -- String to override apiVersion of autoscaling rendered by this helm chart
  autoscaling: "" # autoscaling/v2
  # -- String to override apiVersion of GKE resources rendered by this helm chart
  cloudgoogle: "" # cloud.google.com/v1
  # -- String to override apiVersion of monitoring CRDs (ServiceMonitor) rendered by this helm chart
  monitoring: "" # monitoring.coreos.com/v1

# -- Restrict Argo to operate only in a single namespace (the namespace of the
# Helm release) by apply Roles and RoleBindings instead of the Cluster
# equivalents, and start workflow-controller with the --namespaced flag. Use it
# in clusters with strict access policy.
singleNamespace: false

workflow:
  serviceAccount:
    # -- Specifies whether a service account should be created
    create: true
    # -- Service account which is used to run workflows
    name: ${ argo_workflows_runner_IRSA_name }
    # -- Annotations applied to created service account
    annotations:
      eks.amazonaws.com/role-arn: ${ argo_workflows_runner_IRSA_arn }
  rbac:
    # -- Adds Role and RoleBinding for the above specified service account to be able to run workflows.
    # A Role and Rolebinding pair is also created for each namespace in controller.workflowNamespaces (see below)
    create: true
    # -- Allows permissions for the Argo Agent. Only required if using http/plugin templates
    agentPermissions: true
    # -- Allows permissions for the Argo Artifact GC pod. Only required if using artifact gc
    artifactGC: true
    # -- Extra service accounts to be added to the RoleBinding
    serviceAccounts: []
      # - name: my-service-account
      #   namespace: my-namespace
    # -- Additional rules for the service account that runs the workflows.
    rules: []


controller:
  image:
    # -- Registry to use for the controller
    registry: quay.io
    # -- Registry to use for the controller
    repository: argoproj/workflow-controller
    # -- Image tag for the workflow controller. Defaults to `.Values.images.tag`.
    tag: ""
  # -- parallelism dictates how many workflows can be running at the same time
  parallelism: 500
  # -- Globally limits the rate at which pods are created.
  # This is intended to mitigate flooding of the Kubernetes API server by workflows with a large amount of
  # parallel nodes.
  resourceRateLimit:
    limit: 10
    burst: 25

  rbac:
    # -- Adds Role and RoleBinding for the controller.
    create: true
    # -- Allows controller to get, list, and watch certain k8s secrets
    secretWhitelist: []
    # -- Allows controller to get, list and watch all k8s secrets. Can only be used if secretWhitelist is empty.
    accessAllSecrets: false
    # -- Allows controller to create and update ConfigMaps. Enables memoization feature
    writeConfigMaps: true

  configMap:
    # -- Create a ConfigMap for the controller
    create: true
    # -- ConfigMap name
    name: "argo-workflows-controller-configmap"
    # -- ConfigMap annotations
    annotations: {}

  # -- Limits the maximum number of incomplete workflows in a namespace
  namespaceParallelism:
  # -- Resolves ongoing, uncommon AWS EKS bug: https://github.com/argoproj/argo-workflows/pull/4224
  initialDelay:
  # -- deploymentAnnotations is an optional map of annotations to be applied to the controller Deployment
  deploymentAnnotations: {}
  # -- podAnnotations is an optional map of annotations to be applied to the controller Pods
  podAnnotations: {}
  # -- Optional labels to add to the controller pods
  podLabels: {}
  # -- SecurityContext to set on the controller pods
  podSecurityContext: {}
  # podPortName: http
  metricsConfig:
    # -- Enables prometheus metrics server
    enabled: true
    # -- Path is the path where metrics are emitted. Must start with a "/".
    path: /metrics
    # -- Frequency at which prometheus scrapes metrics
    interval: 30s
    # -- Port is the port where metrics are emitted
    port: 9090
    # -- How often custom metrics are cleared from memory
    metricsTTL: ""
    # -- Flag that instructs prometheus to ignore metric emission errors.
    ignoreErrors: false
    # --  Flag that use a self-signed cert for TLS
    secure: true
    # -- Container metrics port name
    portName: metrics
    # -- Service metrics port
    servicePort: 8080
    # -- Service metrics port name
    servicePortName: metrics
    # -- Flag to enable headless service
    headlessService: false
    # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.
    ## Ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#honorlabels
    honorLabels: false
    # -- ServiceMonitor relabel configs to apply to samples before scraping
    ## Ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
    relabelings: []
    # -- ServiceMonitor metric relabel configs to apply to samples before ingestion
    ## Ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#endpoint
    metricRelabelings: []
    # -- ServiceMonitor will add labels from the service to the Prometheus metric
    ## Ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#servicemonitorspec
    targetLabels: []
  # -- the controller container's securityContext
  securityContext:
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
  # -- enable Workflow Archive to store the status of workflows. Postgres and MySQL (>= 5.7.8) are available.
  ## Ref: https://argo-workflows.readthedocs.io/en/stable/workflow-archive/
  persistence:
    # -- Save the entire workflow into etcd and DB
    # nodeStatusOffload: true
    # -- Enable archiving of old workflows
    archive: true
    mysql:
      host: ${ argo_workflows_db_host }
      port: ${ argo_workflows_db_port }
      database: ${ argo_workflows_db_name }
      tableName: ${ argo_workflows_db_table_name}
      userNameSecret:
        name: ${ argo_workflows_db_secret_name }
        key: username
      passwordSecret:
        name: ${ argo_workflows_db_secret_name }
        key: password

  # -- Default values that will apply to all Workflows from this controller, unless overridden on the Workflow-level.
  # Only valid for 2.7+
  ## See more: https://argo-workflows.readthedocs.io/en/stable/default-workflow-specs/
  workflowDefaults: {}
  #   spec:
  #     ttlStrategy:
  #       secondsAfterCompletion: 86400
  #     # Ref: https://argo-workflows.readthedocs.io/en/stable/artifact-repository-ref/
  #     artifactRepositoryRef:
  #       configMap: my-artifact-repository # default is "artifact-repositories"
  #       key: v2-s3-artifact-repository # default can be set by the `workflows.argoproj.io/default-artifact-repository` annotation in config map.

  # -- Number of workflow workers
  workflowWorkers: 64 # 32
  # # -- Number of workflow TTL workers
  # workflowTTLWorkers: # 4
  # # -- Number of pod cleanup workers
  # podCleanupWorkers: # 4
  # # -- Number of cron workflow workers
  # # Only valid for 3.5+
  # cronWorkflowWorkers: # 8
  # # -- Restricts the Workflows that the controller will process.
  # # Only valid for 2.9+
  # workflowRestrictions: {}
  #   # templateReferencing: Strict|Secure

  # telemetryConfig controls the path and port for prometheus telemetry. Telemetry is enabled and emitted in the same endpoint
  # as metrics by default, but can be overridden using this config.
  telemetryConfig:
    # -- Enables prometheus telemetry server
    enabled: false
    # -- telemetry path
    path: /telemetry
    # -- Frequency at which prometheus scrapes telemetry data
    interval: 30s
    # -- telemetry container port
    port: 8081
    # -- How often custom metrics are cleared from memory
    metricsTTL: ""
    # -- Flag that instructs prometheus to ignore metric emission errors.
    ignoreErrors: false
    # --  Flag that use a self-signed cert for TLS
    secure: false
    # -- telemetry service port
    servicePort: 8081
    # -- telemetry service port name
    servicePortName: telemetry
  serviceMonitor:
    # -- Enable a prometheus ServiceMonitor
    enabled: true
    # -- Prometheus ServiceMonitor labels
    additionalLabels: {}
    # -- Prometheus ServiceMonitor namespace
    namespace: "" # "monitoring"
  serviceAccount:
    # -- Create a service account for the controller
    create: true
    # -- Service account name
    name: "argo-workflows-controller-sa"
    # -- Labels applied to created service account
    labels: {}
    # -- Annotations applied to created service account
    annotations: {}



  # -- Workflow controller name string
  name: "workflow-controller"

  # -- Specify all namespaces where this workflow controller instance will manage
  # workflows. This controls where the service account and RBAC resources will
  # be created. Only valid when singleNamespace is false.
  workflowNamespaces:
    - ${ argo_workflows_namespace }

  instanceID:
    # -- Configures the controller to filter workflow submissions
    # to only those which have a matching instanceID attribute.
    ## NOTE: If `instanceID.enabled` is set to `true` then either `instanceID.userReleaseName`
    ## or `instanceID.explicitID` must be defined.
    enabled: false
    # -- Use ReleaseName as instanceID
    useReleaseName: false
    # useReleaseName: true

    # -- Use a custom instanceID
    explicitID: ""
    # explicitID: unique-argo-controller-identifier

  logging:
    # -- Set the logging level (one of: `debug`, `info`, `warn`, `error`)
    level: info
    # -- Set the glog logging level
    globallevel: "0"
    # -- Set the logging format (one of: `text`, `json`)
    format: "text"

  # -- Service type of the controller Service
  serviceType: ClusterIP
  # -- Annotations to be applied to the controller Service
  serviceAnnotations: {}
  # -- Optional labels to add to the controller Service
  serviceLabels: {}
  # -- The class of the load balancer implementation
  loadBalancerClass: ""
  # -- Source ranges to allow access to service from. Only applies to service type `LoadBalancer`
  loadBalancerSourceRanges: []

  # -- Resource limits and requests for the controller
  resources: {}

  # -- Configure liveness [probe] for the controller
  # @default -- See [values.yaml]
  livenessProbe:
    httpGet:
      port: 6060
      path: /healthz
    failureThreshold: 3
    initialDelaySeconds: 90
    periodSeconds: 60
    timeoutSeconds: 30

  # -- Extra environment variables to provide to the controller container
  extraEnv:
    - name: DEFAULT_REQUEUE_TIME
      value: '1m'
  #   - name: 'ALWAYS_OFFLOAD_NODE_STATUS'
  #     value: 'true'
    # - name: 'OTEL_EXPORTER_OTLP_METRICS_ENDPOINT'
    #   value: http://0.0.0.0:4317

  # -- Extra arguments to be added to the controller
  extraArgs:
    - --qps=50
    - --burst=75
  # -- Additional volume mounts to the controller main container
  volumeMounts: []
  # -- Additional volumes to the controller pod
  volumes: []
  # -- The number of controller pods to run
  replicas: 1
  # -- The number of revisions to keep.
  revisionHistoryLimit: 10

  pdb:
    # -- Configure [Pod Disruption Budget] for the controller pods
    enabled: false
    # minAvailable: 1
    # maxUnavailable: 1

  # -- [Node selector]
  nodeSelector:
    kubernetes.io/os: linux
  # -- [Tolerations] for use with node taints
  tolerations:
  - key: "argo.com/backend"
    value: "true"
    effect: "NoSchedule"
  # -- Assign custom [affinity] rules
  affinity: {}


server:
  # -- Deploy the Argo Server
  enabled: true
  # -- Service type for server pods
  serviceType: LoadBalancer

  serviceAccount:
    # -- Create a service account for the server
    create: true
    # -- Service account name
    name: ${ argo_workflows_server_IRSA_name }
    annotations:
      # -- Annotations applied to created service account
      eks.amazonaws.com/role-arn: ${ argo_workflows_server_IRSA_arn }
    rbac:
      create: true

  ## Argo Server Horizontal Pod Autoscaler
  autoscaling:
    # -- Enable Horizontal Pod Autoscaler ([HPA]) for the Argo Server
    enabled: true
    minReplicas: 2

  extraArgs:
    - "--auth-mode=server"

  # -- A list of supported authentication modes. Available values are `server`, `client`, or `sso`. If you provide sso, please configure `.Values.server.sso` as well.
  ## Ref: https://argo-workflows.readthedocs.io/en/stable/argo-server-auth-mode/
  authModes: ['server']

  # -- [Tolerations] for use with node taints
  tolerations:
  - key: "argo.com/backend"
    value: "true"
    effect: "NoSchedule"

  serviceAnnotations:
    # see https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/guide/service/annotations/#security-groups
    service.beta.kubernetes.io/aws-load-balancer-security-groups: ${ argo_frontend_securitygroup }

## Artifact Repository Configuration
# -- Use static credentials for S3 (eg. when not using AWS IRSA)
useStaticCredentials: false
artifactRepository:
  # -- Archive the main container logs as an artifact
  archiveLogs: true
  # -- Store artifact in a S3-compliant object store
  # @default -- See [values.yaml]
  s3:
    bucket: ${ argo_workflows_bucket }
    # keyFormat: fmriresults01/abcd-mproc-release5
    endpoint: s3-accelerate.amazonaws.com
    region: ${ region }
    useSDKcreds: true
    encryptionOptions:
      enableEncryption: true

useDefaultArtifactRepo: true

